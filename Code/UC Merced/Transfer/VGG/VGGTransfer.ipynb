{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of VGGNet2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNSYBFSkUXDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMsLh3MyU4um",
        "colab_type": "code",
        "outputId": "6ba0cee0-7139-4bf2-fb56-56d0d02641c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvZqLOrwVUxK",
        "colab_type": "code",
        "outputId": "275801bd-a7b1-4efc-c811-46b9c68cc376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "from contextlib import suppress\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import warnings\n",
        "from zipfile import ZipFile\n",
        "\n",
        "from skimage.io import imread, imsave\n",
        "\n",
        "from keras import applications\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Dropout, Flatten\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZEolmjjU5S2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvDLkYoXi0om",
        "colab_type": "code",
        "outputId": "457795c0-c42f-4f86-d443-bb17a164eae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "!pwd\n",
        "%cd \"drive/My Drive/CV_Project\"\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/drive/My Drive/CV_Project\n",
            "/content/drive/My Drive/CV_Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJuyW7I8gXsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = os.listdir('UCMerced_LandUse/Train/')\n",
        "target_dirs = {target: './UCMerced_LandUse/' + target for target in ['Train', 'Validation', 'Test']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0MCiyVhiwyW",
        "colab_type": "code",
        "outputId": "f7247d1d-4732-4b42-b8fd-b750c18120b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(class_names)\n",
        "print(target_dirs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['storagetanks', 'tenniscourt', 'sparseresidential', 'river', 'runway', 'parkinglot', 'overpass', 'harbor', 'intersection', 'mobilehomepark', 'mediumresidential', 'golfcourse', 'freeway', 'denseresidential', 'forest', 'buildings', 'chaparral', 'beach', 'baseballdiamond', 'airplane', 'agricultural']\n",
            "{'Train': './UCMerced_LandUse/Train', 'Validation': './UCMerced_LandUse/Validation', 'Test': './UCMerced_LandUse/Test'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBqv_-ARi_qX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_bottleneck_features(model, dataset, batch_size=64):\n",
        "  print(f'Generating \"{dataset}\" bottleneck predictions')\n",
        "  image_data_gen = ImageDataGenerator(rescale=1/255.0)\n",
        "  image_generator = image_data_gen.flow_from_directory(target_dirs[dataset],\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        shuffle=False)\n",
        "  image_count = 0\n",
        "  X_batches, Y_batches = [], []\n",
        "  for X, Y in image_generator:\n",
        "    X_batches.append(model.predict_on_batch(X))\n",
        "    Y_batches.append(Y)\n",
        "    image_count += X.shape[0]\n",
        "    # Must interrupt image_generator\n",
        "    if image_count >= image_generator.n:\n",
        "      break\n",
        "  X = np.concatenate(X_batches)\n",
        "  Y = np.concatenate(Y_batches)\n",
        "  return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fJtrFDMlLTR",
        "colab_type": "code",
        "outputId": "5e85da99-3a5e-48d8-88df-330e125125e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "pretrained_model = applications.VGG16(include_top=False, weights='imagenet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 6s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abhub4-JlNnZ",
        "colab_type": "code",
        "outputId": "400e2656-0810-499f-e3d7-df24d84e7375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "num_classes = len(class_names)\n",
        "X, Y = dict(), dict()\n",
        "for dataset in ['Train', 'Validation', 'Test']:\n",
        "    # Extract bottleneck features from pretrained model, predicting from \"dataset\" directory\n",
        "    X[dataset], Y[dataset] = get_bottleneck_features(pretrained_model, dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating \"Train\" bottleneck predictions\n",
            "Found 1785 images belonging to 21 classes.\n",
            "Generating \"Validation\" bottleneck predictions\n",
            "Found 210 images belonging to 21 classes.\n",
            "Generating \"Test\" bottleneck predictions\n",
            "Found 210 images belonging to 21 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8IQsRJSmSai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_fully_connected(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Create a fully-connected model to train or test on UC Merced dataset.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=input_shape))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWMySc0_lc2I",
        "colab_type": "code",
        "outputId": "1a241436-f5d1-4142-e81f-712fbb44f619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = build_fully_connected(input_shape=X['Train'].shape[1:], num_classes=num_classes)\n",
        "adam = optimizers.Adam(lr=0.0001)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_fit_history = model.fit(X['Train'], Y['Train'], batch_size=64, epochs=300,\n",
        "                              verbose=2, validation_data=(X['Validation'], Y['Validation']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1785 samples, validate on 210 samples\n",
            "Epoch 1/300\n",
            " - 1s - loss: 2.2836 - acc: 0.3462 - val_loss: 1.3959 - val_acc: 0.7095\n",
            "Epoch 2/300\n",
            " - 0s - loss: 1.1002 - acc: 0.6947 - val_loss: 0.9539 - val_acc: 0.7619\n",
            "Epoch 3/300\n",
            " - 0s - loss: 0.6933 - acc: 0.8129 - val_loss: 0.7961 - val_acc: 0.7571\n",
            "Epoch 4/300\n",
            " - 0s - loss: 0.4999 - acc: 0.8644 - val_loss: 0.7093 - val_acc: 0.7667\n",
            "Epoch 5/300\n",
            " - 0s - loss: 0.3630 - acc: 0.9143 - val_loss: 0.6479 - val_acc: 0.7905\n",
            "Epoch 6/300\n",
            " - 0s - loss: 0.2844 - acc: 0.9412 - val_loss: 0.6392 - val_acc: 0.7762\n",
            "Epoch 7/300\n",
            " - 0s - loss: 0.2391 - acc: 0.9462 - val_loss: 0.5994 - val_acc: 0.8143\n",
            "Epoch 8/300\n",
            " - 0s - loss: 0.1992 - acc: 0.9625 - val_loss: 0.5929 - val_acc: 0.8000\n",
            "Epoch 9/300\n",
            " - 1s - loss: 0.1619 - acc: 0.9737 - val_loss: 0.5480 - val_acc: 0.8048\n",
            "Epoch 10/300\n",
            " - 0s - loss: 0.1384 - acc: 0.9742 - val_loss: 0.5720 - val_acc: 0.8000\n",
            "Epoch 11/300\n",
            " - 0s - loss: 0.1222 - acc: 0.9798 - val_loss: 0.5704 - val_acc: 0.8048\n",
            "Epoch 12/300\n",
            " - 0s - loss: 0.1018 - acc: 0.9882 - val_loss: 0.5285 - val_acc: 0.8238\n",
            "Epoch 13/300\n",
            " - 0s - loss: 0.0882 - acc: 0.9899 - val_loss: 0.5400 - val_acc: 0.8000\n",
            "Epoch 14/300\n",
            " - 0s - loss: 0.0813 - acc: 0.9910 - val_loss: 0.5274 - val_acc: 0.8286\n",
            "Epoch 15/300\n",
            " - 0s - loss: 0.0800 - acc: 0.9894 - val_loss: 0.5291 - val_acc: 0.8190\n",
            "Epoch 16/300\n",
            " - 0s - loss: 0.0670 - acc: 0.9938 - val_loss: 0.5264 - val_acc: 0.8190\n",
            "Epoch 17/300\n",
            " - 0s - loss: 0.0634 - acc: 0.9944 - val_loss: 0.5271 - val_acc: 0.8143\n",
            "Epoch 18/300\n",
            " - 0s - loss: 0.0506 - acc: 0.9983 - val_loss: 0.4999 - val_acc: 0.8095\n",
            "Epoch 19/300\n",
            " - 0s - loss: 0.0518 - acc: 0.9938 - val_loss: 0.5130 - val_acc: 0.8238\n",
            "Epoch 20/300\n",
            " - 0s - loss: 0.0492 - acc: 0.9966 - val_loss: 0.4966 - val_acc: 0.8333\n",
            "Epoch 21/300\n",
            " - 1s - loss: 0.0380 - acc: 0.9955 - val_loss: 0.4946 - val_acc: 0.8381\n",
            "Epoch 22/300\n",
            " - 0s - loss: 0.0406 - acc: 0.9972 - val_loss: 0.4842 - val_acc: 0.8476\n",
            "Epoch 23/300\n",
            " - 0s - loss: 0.0388 - acc: 0.9978 - val_loss: 0.4949 - val_acc: 0.8238\n",
            "Epoch 24/300\n",
            " - 0s - loss: 0.0334 - acc: 0.9983 - val_loss: 0.4916 - val_acc: 0.8190\n",
            "Epoch 25/300\n",
            " - 1s - loss: 0.0349 - acc: 0.9966 - val_loss: 0.5054 - val_acc: 0.8190\n",
            "Epoch 26/300\n",
            " - 0s - loss: 0.0322 - acc: 0.9972 - val_loss: 0.5014 - val_acc: 0.8333\n",
            "Epoch 27/300\n",
            " - 0s - loss: 0.0304 - acc: 0.9972 - val_loss: 0.4878 - val_acc: 0.8190\n",
            "Epoch 28/300\n",
            " - 0s - loss: 0.0256 - acc: 0.9994 - val_loss: 0.5223 - val_acc: 0.8190\n",
            "Epoch 29/300\n",
            " - 0s - loss: 0.0249 - acc: 0.9989 - val_loss: 0.4936 - val_acc: 0.8190\n",
            "Epoch 30/300\n",
            " - 0s - loss: 0.0232 - acc: 0.9994 - val_loss: 0.5309 - val_acc: 0.8190\n",
            "Epoch 31/300\n",
            " - 0s - loss: 0.0260 - acc: 0.9972 - val_loss: 0.5174 - val_acc: 0.8286\n",
            "Epoch 32/300\n",
            " - 0s - loss: 0.0190 - acc: 0.9994 - val_loss: 0.5190 - val_acc: 0.8095\n",
            "Epoch 33/300\n",
            " - 0s - loss: 0.0171 - acc: 0.9994 - val_loss: 0.4934 - val_acc: 0.8143\n",
            "Epoch 34/300\n",
            " - 0s - loss: 0.0194 - acc: 0.9994 - val_loss: 0.5169 - val_acc: 0.8143\n",
            "Epoch 35/300\n",
            " - 0s - loss: 0.0191 - acc: 0.9989 - val_loss: 0.5273 - val_acc: 0.8143\n",
            "Epoch 36/300\n",
            " - 0s - loss: 0.0198 - acc: 0.9983 - val_loss: 0.5083 - val_acc: 0.8143\n",
            "Epoch 37/300\n",
            " - 0s - loss: 0.0180 - acc: 0.9994 - val_loss: 0.4892 - val_acc: 0.8095\n",
            "Epoch 38/300\n",
            " - 0s - loss: 0.0157 - acc: 1.0000 - val_loss: 0.5057 - val_acc: 0.8190\n",
            "Epoch 39/300\n",
            " - 0s - loss: 0.0151 - acc: 0.9989 - val_loss: 0.4994 - val_acc: 0.8190\n",
            "Epoch 40/300\n",
            " - 0s - loss: 0.0152 - acc: 0.9994 - val_loss: 0.5074 - val_acc: 0.8190\n",
            "Epoch 41/300\n",
            " - 0s - loss: 0.0162 - acc: 0.9983 - val_loss: 0.4879 - val_acc: 0.8190\n",
            "Epoch 42/300\n",
            " - 0s - loss: 0.0143 - acc: 0.9989 - val_loss: 0.4986 - val_acc: 0.8238\n",
            "Epoch 43/300\n",
            " - 0s - loss: 0.0143 - acc: 1.0000 - val_loss: 0.4777 - val_acc: 0.8476\n",
            "Epoch 44/300\n",
            " - 0s - loss: 0.0114 - acc: 0.9994 - val_loss: 0.4745 - val_acc: 0.8286\n",
            "Epoch 45/300\n",
            " - 0s - loss: 0.0117 - acc: 1.0000 - val_loss: 0.4850 - val_acc: 0.8333\n",
            "Epoch 46/300\n",
            " - 1s - loss: 0.0101 - acc: 1.0000 - val_loss: 0.4860 - val_acc: 0.8238\n",
            "Epoch 47/300\n",
            " - 0s - loss: 0.0100 - acc: 1.0000 - val_loss: 0.4843 - val_acc: 0.8333\n",
            "Epoch 48/300\n",
            " - 0s - loss: 0.0096 - acc: 0.9989 - val_loss: 0.4918 - val_acc: 0.8286\n",
            "Epoch 49/300\n",
            " - 0s - loss: 0.0102 - acc: 1.0000 - val_loss: 0.4788 - val_acc: 0.8476\n",
            "Epoch 50/300\n",
            " - 0s - loss: 0.0089 - acc: 1.0000 - val_loss: 0.4858 - val_acc: 0.8429\n",
            "Epoch 51/300\n",
            " - 0s - loss: 0.0095 - acc: 1.0000 - val_loss: 0.4956 - val_acc: 0.8286\n",
            "Epoch 52/300\n",
            " - 0s - loss: 0.0083 - acc: 0.9994 - val_loss: 0.4895 - val_acc: 0.8333\n",
            "Epoch 53/300\n",
            " - 0s - loss: 0.0098 - acc: 1.0000 - val_loss: 0.4946 - val_acc: 0.8429\n",
            "Epoch 54/300\n",
            " - 0s - loss: 0.0086 - acc: 0.9994 - val_loss: 0.4856 - val_acc: 0.8238\n",
            "Epoch 55/300\n",
            " - 0s - loss: 0.0087 - acc: 1.0000 - val_loss: 0.5003 - val_acc: 0.8286\n",
            "Epoch 56/300\n",
            " - 0s - loss: 0.0088 - acc: 0.9994 - val_loss: 0.5178 - val_acc: 0.8190\n",
            "Epoch 57/300\n",
            " - 0s - loss: 0.0089 - acc: 0.9994 - val_loss: 0.4884 - val_acc: 0.8381\n",
            "Epoch 58/300\n",
            " - 0s - loss: 0.0077 - acc: 1.0000 - val_loss: 0.5047 - val_acc: 0.8333\n",
            "Epoch 59/300\n",
            " - 0s - loss: 0.0082 - acc: 0.9989 - val_loss: 0.4919 - val_acc: 0.8286\n",
            "Epoch 60/300\n",
            " - 0s - loss: 0.0111 - acc: 0.9994 - val_loss: 0.5201 - val_acc: 0.8238\n",
            "Epoch 61/300\n",
            " - 0s - loss: 0.0081 - acc: 1.0000 - val_loss: 0.4944 - val_acc: 0.8238\n",
            "Epoch 62/300\n",
            " - 0s - loss: 0.0066 - acc: 0.9994 - val_loss: 0.5030 - val_acc: 0.8286\n",
            "Epoch 63/300\n",
            " - 0s - loss: 0.0063 - acc: 0.9994 - val_loss: 0.5001 - val_acc: 0.8333\n",
            "Epoch 64/300\n",
            " - 0s - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5009 - val_acc: 0.8429\n",
            "Epoch 65/300\n",
            " - 0s - loss: 0.0068 - acc: 1.0000 - val_loss: 0.4938 - val_acc: 0.8286\n",
            "Epoch 66/300\n",
            " - 0s - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5007 - val_acc: 0.8333\n",
            "Epoch 67/300\n",
            " - 0s - loss: 0.0072 - acc: 0.9989 - val_loss: 0.5158 - val_acc: 0.8190\n",
            "Epoch 68/300\n",
            " - 0s - loss: 0.0062 - acc: 1.0000 - val_loss: 0.4984 - val_acc: 0.8286\n",
            "Epoch 69/300\n",
            " - 0s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.5043 - val_acc: 0.8286\n",
            "Epoch 70/300\n",
            " - 0s - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5183 - val_acc: 0.8143\n",
            "Epoch 71/300\n",
            " - 0s - loss: 0.0058 - acc: 1.0000 - val_loss: 0.4929 - val_acc: 0.8476\n",
            "Epoch 72/300\n",
            " - 0s - loss: 0.0053 - acc: 0.9994 - val_loss: 0.5239 - val_acc: 0.8333\n",
            "Epoch 73/300\n",
            " - 0s - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5021 - val_acc: 0.8333\n",
            "Epoch 74/300\n",
            " - 0s - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5081 - val_acc: 0.8524\n",
            "Epoch 75/300\n",
            " - 0s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5202 - val_acc: 0.8238\n",
            "Epoch 76/300\n",
            " - 0s - loss: 0.0050 - acc: 1.0000 - val_loss: 0.5156 - val_acc: 0.8381\n",
            "Epoch 77/300\n",
            " - 1s - loss: 0.0048 - acc: 0.9994 - val_loss: 0.5245 - val_acc: 0.8286\n",
            "Epoch 78/300\n",
            " - 0s - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5132 - val_acc: 0.8286\n",
            "Epoch 79/300\n",
            " - 0s - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5122 - val_acc: 0.8286\n",
            "Epoch 80/300\n",
            " - 0s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5108 - val_acc: 0.8238\n",
            "Epoch 81/300\n",
            " - 0s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.5029 - val_acc: 0.8381\n",
            "Epoch 82/300\n",
            " - 0s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.5114 - val_acc: 0.8286\n",
            "Epoch 83/300\n",
            " - 0s - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5188 - val_acc: 0.8333\n",
            "Epoch 84/300\n",
            " - 0s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.5277 - val_acc: 0.8286\n",
            "Epoch 85/300\n",
            " - 0s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5236 - val_acc: 0.8381\n",
            "Epoch 86/300\n",
            " - 0s - loss: 0.0033 - acc: 1.0000 - val_loss: 0.5243 - val_acc: 0.8333\n",
            "Epoch 87/300\n",
            " - 0s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.5266 - val_acc: 0.8333\n",
            "Epoch 88/300\n",
            " - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5171 - val_acc: 0.8238\n",
            "Epoch 89/300\n",
            " - 0s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.5043 - val_acc: 0.8429\n",
            "Epoch 90/300\n",
            " - 0s - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5158 - val_acc: 0.8190\n",
            "Epoch 91/300\n",
            " - 0s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.4851 - val_acc: 0.8429\n",
            "Epoch 92/300\n",
            " - 0s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.5025 - val_acc: 0.8333\n",
            "Epoch 93/300\n",
            " - 0s - loss: 0.0052 - acc: 0.9994 - val_loss: 0.5067 - val_acc: 0.8333\n",
            "Epoch 94/300\n",
            " - 0s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.4864 - val_acc: 0.8619\n",
            "Epoch 95/300\n",
            " - 0s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.4741 - val_acc: 0.8571\n",
            "Epoch 96/300\n",
            " - 0s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.5071 - val_acc: 0.8429\n",
            "Epoch 97/300\n",
            " - 0s - loss: 0.0039 - acc: 1.0000 - val_loss: 0.4916 - val_acc: 0.8524\n",
            "Epoch 98/300\n",
            " - 0s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.4940 - val_acc: 0.8476\n",
            "Epoch 99/300\n",
            " - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.4958 - val_acc: 0.8619\n",
            "Epoch 100/300\n",
            " - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.4948 - val_acc: 0.8571\n",
            "Epoch 101/300\n",
            " - 1s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.4724 - val_acc: 0.8619\n",
            "Epoch 102/300\n",
            " - 0s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.5093 - val_acc: 0.8381\n",
            "Epoch 103/300\n",
            " - 0s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.4912 - val_acc: 0.8524\n",
            "Epoch 104/300\n",
            " - 1s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.4878 - val_acc: 0.8286\n",
            "Epoch 105/300\n",
            " - 0s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.5103 - val_acc: 0.8429\n",
            "Epoch 106/300\n",
            " - 0s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.4761 - val_acc: 0.8714\n",
            "Epoch 107/300\n",
            " - 0s - loss: 0.0045 - acc: 0.9994 - val_loss: 0.5074 - val_acc: 0.8524\n",
            "Epoch 108/300\n",
            " - 0s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5225 - val_acc: 0.8619\n",
            "Epoch 109/300\n",
            " - 0s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.4834 - val_acc: 0.8476\n",
            "Epoch 110/300\n",
            " - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.4874 - val_acc: 0.8667\n",
            "Epoch 111/300\n",
            " - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5023 - val_acc: 0.8667\n",
            "Epoch 112/300\n",
            " - 0s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.4869 - val_acc: 0.8524\n",
            "Epoch 113/300\n",
            " - 0s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.5101 - val_acc: 0.8286\n",
            "Epoch 114/300\n",
            " - 0s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5040 - val_acc: 0.8429\n",
            "Epoch 115/300\n",
            " - 0s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.5235 - val_acc: 0.8524\n",
            "Epoch 116/300\n",
            " - 0s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.4833 - val_acc: 0.8667\n",
            "Epoch 117/300\n",
            " - 0s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5168 - val_acc: 0.8524\n",
            "Epoch 118/300\n",
            " - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5109 - val_acc: 0.8476\n",
            "Epoch 119/300\n",
            " - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5516 - val_acc: 0.8286\n",
            "Epoch 120/300\n",
            " - 0s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5276 - val_acc: 0.8286\n",
            "Epoch 121/300\n",
            " - 1s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.4962 - val_acc: 0.8667\n",
            "Epoch 122/300\n",
            " - 0s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.4982 - val_acc: 0.8286\n",
            "Epoch 123/300\n",
            " - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5211 - val_acc: 0.8429\n",
            "Epoch 124/300\n",
            " - 0s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5287 - val_acc: 0.8333\n",
            "Epoch 125/300\n",
            " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5321 - val_acc: 0.8381\n",
            "Epoch 126/300\n",
            " - 0s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.5609 - val_acc: 0.8333\n",
            "Epoch 127/300\n",
            " - 0s - loss: 0.0025 - acc: 0.9994 - val_loss: 0.5269 - val_acc: 0.8619\n",
            "Epoch 128/300\n",
            " - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5457 - val_acc: 0.8333\n",
            "Epoch 129/300\n",
            " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5517 - val_acc: 0.8333\n",
            "Epoch 130/300\n",
            " - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5482 - val_acc: 0.8381\n",
            "Epoch 131/300\n",
            " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5381 - val_acc: 0.8381\n",
            "Epoch 132/300\n",
            " - 1s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.5378 - val_acc: 0.8286\n",
            "Epoch 133/300\n",
            " - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5335 - val_acc: 0.8476\n",
            "Epoch 134/300\n",
            " - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5302 - val_acc: 0.8476\n",
            "Epoch 135/300\n",
            " - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5292 - val_acc: 0.8476\n",
            "Epoch 136/300\n",
            " - 1s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5378 - val_acc: 0.8333\n",
            "Epoch 137/300\n",
            " - 0s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5352 - val_acc: 0.8667\n",
            "Epoch 138/300\n",
            " - 0s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5202 - val_acc: 0.8381\n",
            "Epoch 139/300\n",
            " - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.5434 - val_acc: 0.8381\n",
            "Epoch 140/300\n",
            " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5528 - val_acc: 0.8143\n",
            "Epoch 141/300\n",
            " - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5722 - val_acc: 0.8524\n",
            "Epoch 142/300\n",
            " - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5418 - val_acc: 0.8286\n",
            "Epoch 143/300\n",
            " - 0s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5522 - val_acc: 0.8476\n",
            "Epoch 144/300\n",
            " - 0s - loss: 9.7764e-04 - acc: 1.0000 - val_loss: 0.5329 - val_acc: 0.8524\n",
            "Epoch 145/300\n",
            " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5472 - val_acc: 0.8143\n",
            "Epoch 146/300\n",
            " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5566 - val_acc: 0.8524\n",
            "Epoch 147/300\n",
            " - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5943 - val_acc: 0.8286\n",
            "Epoch 148/300\n",
            " - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5681 - val_acc: 0.8333\n",
            "Epoch 149/300\n",
            " - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.5248 - val_acc: 0.8571\n",
            "Epoch 150/300\n",
            " - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5276 - val_acc: 0.8429\n",
            "Epoch 151/300\n",
            " - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5151 - val_acc: 0.8524\n",
            "Epoch 152/300\n",
            " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5703 - val_acc: 0.8333\n",
            "Epoch 153/300\n",
            " - 0s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.4889 - val_acc: 0.8524\n",
            "Epoch 154/300\n",
            " - 0s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.5558 - val_acc: 0.8429\n",
            "Epoch 155/300\n",
            " - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5619 - val_acc: 0.8095\n",
            "Epoch 156/300\n",
            " - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5421 - val_acc: 0.8286\n",
            "Epoch 157/300\n",
            " - 1s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.5546 - val_acc: 0.8571\n",
            "Epoch 158/300\n",
            " - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5301 - val_acc: 0.8238\n",
            "Epoch 159/300\n",
            " - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5836 - val_acc: 0.8333\n",
            "Epoch 160/300\n",
            " - 0s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.5646 - val_acc: 0.8381\n",
            "Epoch 161/300\n",
            " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5608 - val_acc: 0.8381\n",
            "Epoch 162/300\n",
            " - 0s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5676 - val_acc: 0.8381\n",
            "Epoch 163/300\n",
            " - 0s - loss: 8.0733e-04 - acc: 1.0000 - val_loss: 0.5570 - val_acc: 0.8429\n",
            "Epoch 164/300\n",
            " - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5632 - val_acc: 0.8429\n",
            "Epoch 165/300\n",
            " - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5465 - val_acc: 0.8333\n",
            "Epoch 166/300\n",
            " - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5494 - val_acc: 0.8286\n",
            "Epoch 167/300\n",
            " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5803 - val_acc: 0.8143\n",
            "Epoch 168/300\n",
            " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.5700 - val_acc: 0.8619\n",
            "Epoch 169/300\n",
            " - 0s - loss: 8.6477e-04 - acc: 1.0000 - val_loss: 0.5933 - val_acc: 0.8619\n",
            "Epoch 170/300\n",
            " - 0s - loss: 6.8403e-04 - acc: 1.0000 - val_loss: 0.5706 - val_acc: 0.8333\n",
            "Epoch 171/300\n",
            " - 0s - loss: 6.7875e-04 - acc: 1.0000 - val_loss: 0.5711 - val_acc: 0.8238\n",
            "Epoch 172/300\n",
            " - 0s - loss: 7.7759e-04 - acc: 1.0000 - val_loss: 0.5636 - val_acc: 0.8429\n",
            "Epoch 173/300\n",
            " - 0s - loss: 6.7981e-04 - acc: 1.0000 - val_loss: 0.5613 - val_acc: 0.8571\n",
            "Epoch 174/300\n",
            " - 0s - loss: 6.8169e-04 - acc: 1.0000 - val_loss: 0.5598 - val_acc: 0.8381\n",
            "Epoch 175/300\n",
            " - 0s - loss: 7.4119e-04 - acc: 1.0000 - val_loss: 0.5628 - val_acc: 0.8286\n",
            "Epoch 176/300\n",
            " - 0s - loss: 8.7772e-04 - acc: 1.0000 - val_loss: 0.5580 - val_acc: 0.8429\n",
            "Epoch 177/300\n",
            " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5593 - val_acc: 0.8571\n",
            "Epoch 178/300\n",
            " - 0s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.5476 - val_acc: 0.8429\n",
            "Epoch 179/300\n",
            " - 0s - loss: 8.5592e-04 - acc: 1.0000 - val_loss: 0.5525 - val_acc: 0.8286\n",
            "Epoch 180/300\n",
            " - 0s - loss: 7.8501e-04 - acc: 1.0000 - val_loss: 0.6062 - val_acc: 0.8381\n",
            "Epoch 181/300\n",
            " - 0s - loss: 7.3265e-04 - acc: 1.0000 - val_loss: 0.5614 - val_acc: 0.8524\n",
            "Epoch 182/300\n",
            " - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6296 - val_acc: 0.8048\n",
            "Epoch 183/300\n",
            " - 0s - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6145 - val_acc: 0.8333\n",
            "Epoch 184/300\n",
            " - 0s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.5564 - val_acc: 0.8429\n",
            "Epoch 185/300\n",
            " - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6772 - val_acc: 0.8095\n",
            "Epoch 186/300\n",
            " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5914 - val_acc: 0.8286\n",
            "Epoch 187/300\n",
            " - 0s - loss: 9.2689e-04 - acc: 1.0000 - val_loss: 0.5873 - val_acc: 0.8238\n",
            "Epoch 188/300\n",
            " - 0s - loss: 6.7051e-04 - acc: 1.0000 - val_loss: 0.5754 - val_acc: 0.8571\n",
            "Epoch 189/300\n",
            " - 0s - loss: 5.2811e-04 - acc: 1.0000 - val_loss: 0.5909 - val_acc: 0.8381\n",
            "Epoch 190/300\n",
            " - 0s - loss: 7.8171e-04 - acc: 1.0000 - val_loss: 0.5814 - val_acc: 0.8381\n",
            "Epoch 191/300\n",
            " - 0s - loss: 7.3809e-04 - acc: 1.0000 - val_loss: 0.5949 - val_acc: 0.8381\n",
            "Epoch 192/300\n",
            " - 0s - loss: 0.0014 - acc: 0.9994 - val_loss: 0.5944 - val_acc: 0.8429\n",
            "Epoch 193/300\n",
            " - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6229 - val_acc: 0.8143\n",
            "Epoch 194/300\n",
            " - 1s - loss: 0.0032 - acc: 0.9994 - val_loss: 0.6302 - val_acc: 0.8190\n",
            "Epoch 195/300\n",
            " - 0s - loss: 0.0060 - acc: 0.9989 - val_loss: 0.6624 - val_acc: 0.8238\n",
            "Epoch 196/300\n",
            " - 0s - loss: 0.0155 - acc: 0.9961 - val_loss: 0.6134 - val_acc: 0.8190\n",
            "Epoch 197/300\n",
            " - 0s - loss: 0.0313 - acc: 0.9899 - val_loss: 0.6742 - val_acc: 0.8190\n",
            "Epoch 198/300\n",
            " - 0s - loss: 0.0401 - acc: 0.9894 - val_loss: 0.6242 - val_acc: 0.8238\n",
            "Epoch 199/300\n",
            " - 0s - loss: 0.0210 - acc: 0.9972 - val_loss: 0.6705 - val_acc: 0.8048\n",
            "Epoch 200/300\n",
            " - 0s - loss: 0.0114 - acc: 0.9989 - val_loss: 0.6477 - val_acc: 0.8238\n",
            "Epoch 201/300\n",
            " - 1s - loss: 0.0094 - acc: 0.9989 - val_loss: 0.6266 - val_acc: 0.8048\n",
            "Epoch 202/300\n",
            " - 0s - loss: 0.0049 - acc: 0.9994 - val_loss: 0.5965 - val_acc: 0.8429\n",
            "Epoch 203/300\n",
            " - 0s - loss: 0.0049 - acc: 0.9994 - val_loss: 0.6525 - val_acc: 0.8190\n",
            "Epoch 204/300\n",
            " - 0s - loss: 0.0034 - acc: 0.9994 - val_loss: 0.6570 - val_acc: 0.8571\n",
            "Epoch 205/300\n",
            " - 0s - loss: 0.0038 - acc: 0.9994 - val_loss: 0.6336 - val_acc: 0.8190\n",
            "Epoch 206/300\n",
            " - 0s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6392 - val_acc: 0.8143\n",
            "Epoch 207/300\n",
            " - 0s - loss: 0.0030 - acc: 0.9994 - val_loss: 0.7041 - val_acc: 0.8286\n",
            "Epoch 208/300\n",
            " - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6614 - val_acc: 0.8333\n",
            "Epoch 209/300\n",
            " - 0s - loss: 0.0037 - acc: 0.9994 - val_loss: 0.7444 - val_acc: 0.8286\n",
            "Epoch 210/300\n",
            " - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6796 - val_acc: 0.8190\n",
            "Epoch 211/300\n",
            " - 1s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.7027 - val_acc: 0.8286\n",
            "Epoch 212/300\n",
            " - 0s - loss: 0.0028 - acc: 0.9989 - val_loss: 0.6692 - val_acc: 0.8000\n",
            "Epoch 213/300\n",
            " - 0s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.6550 - val_acc: 0.8286\n",
            "Epoch 214/300\n",
            " - 0s - loss: 0.0040 - acc: 0.9994 - val_loss: 0.6169 - val_acc: 0.8381\n",
            "Epoch 215/300\n",
            " - 0s - loss: 0.0044 - acc: 0.9994 - val_loss: 0.6173 - val_acc: 0.8571\n",
            "Epoch 216/300\n",
            " - 0s - loss: 0.0053 - acc: 1.0000 - val_loss: 0.7399 - val_acc: 0.8238\n",
            "Epoch 217/300\n",
            " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.7127 - val_acc: 0.8286\n",
            "Epoch 218/300\n",
            " - 0s - loss: 0.0028 - acc: 0.9994 - val_loss: 0.6329 - val_acc: 0.8381\n",
            "Epoch 219/300\n",
            " - 0s - loss: 0.0090 - acc: 0.9966 - val_loss: 0.6881 - val_acc: 0.8429\n",
            "Epoch 220/300\n",
            " - 0s - loss: 0.0057 - acc: 0.9994 - val_loss: 0.6505 - val_acc: 0.8476\n",
            "Epoch 221/300\n",
            " - 0s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6383 - val_acc: 0.8286\n",
            "Epoch 222/300\n",
            " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.7051 - val_acc: 0.8190\n",
            "Epoch 223/300\n",
            " - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.5879 - val_acc: 0.8333\n",
            "Epoch 224/300\n",
            " - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6139 - val_acc: 0.8333\n",
            "Epoch 225/300\n",
            " - 0s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6152 - val_acc: 0.8524\n",
            "Epoch 226/300\n",
            " - 0s - loss: 0.0027 - acc: 0.9994 - val_loss: 0.6340 - val_acc: 0.8238\n",
            "Epoch 227/300\n",
            " - 0s - loss: 0.0028 - acc: 0.9994 - val_loss: 0.6604 - val_acc: 0.8190\n",
            "Epoch 228/300\n",
            " - 1s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.6260 - val_acc: 0.8571\n",
            "Epoch 229/300\n",
            " - 0s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6062 - val_acc: 0.8429\n",
            "Epoch 230/300\n",
            " - 0s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.6137 - val_acc: 0.8476\n",
            "Epoch 231/300\n",
            " - 1s - loss: 8.9263e-04 - acc: 1.0000 - val_loss: 0.5575 - val_acc: 0.8524\n",
            "Epoch 232/300\n",
            " - 0s - loss: 0.0029 - acc: 0.9994 - val_loss: 0.6875 - val_acc: 0.8238\n",
            "Epoch 233/300\n",
            " - 0s - loss: 0.0028 - acc: 0.9994 - val_loss: 0.7215 - val_acc: 0.8286\n",
            "Epoch 234/300\n",
            " - 0s - loss: 0.0028 - acc: 0.9994 - val_loss: 0.7192 - val_acc: 0.8143\n",
            "Epoch 235/300\n",
            " - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6392 - val_acc: 0.8429\n",
            "Epoch 236/300\n",
            " - 0s - loss: 9.5149e-04 - acc: 1.0000 - val_loss: 0.6213 - val_acc: 0.8429\n",
            "Epoch 237/300\n",
            " - 0s - loss: 9.7357e-04 - acc: 1.0000 - val_loss: 0.6472 - val_acc: 0.8429\n",
            "Epoch 238/300\n",
            " - 0s - loss: 0.0019 - acc: 0.9994 - val_loss: 0.7242 - val_acc: 0.8381\n",
            "Epoch 239/300\n",
            " - 1s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.6364 - val_acc: 0.8286\n",
            "Epoch 240/300\n",
            " - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6655 - val_acc: 0.8286\n",
            "Epoch 241/300\n",
            " - 0s - loss: 0.0011 - acc: 0.9994 - val_loss: 0.6393 - val_acc: 0.8571\n",
            "Epoch 242/300\n",
            " - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.6357 - val_acc: 0.8286\n",
            "Epoch 243/300\n",
            " - 0s - loss: 9.9779e-04 - acc: 1.0000 - val_loss: 0.6740 - val_acc: 0.8714\n",
            "Epoch 244/300\n",
            " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.6607 - val_acc: 0.8429\n",
            "Epoch 245/300\n",
            " - 0s - loss: 9.8032e-04 - acc: 1.0000 - val_loss: 0.7148 - val_acc: 0.8190\n",
            "Epoch 246/300\n",
            " - 0s - loss: 7.0440e-04 - acc: 1.0000 - val_loss: 0.7101 - val_acc: 0.8238\n",
            "Epoch 247/300\n",
            " - 0s - loss: 4.4272e-04 - acc: 1.0000 - val_loss: 0.6737 - val_acc: 0.8333\n",
            "Epoch 248/300\n",
            " - 0s - loss: 5.6284e-04 - acc: 1.0000 - val_loss: 0.6856 - val_acc: 0.8333\n",
            "Epoch 249/300\n",
            " - 0s - loss: 2.7373e-04 - acc: 1.0000 - val_loss: 0.6782 - val_acc: 0.8381\n",
            "Epoch 250/300\n",
            " - 0s - loss: 3.6897e-04 - acc: 1.0000 - val_loss: 0.6736 - val_acc: 0.8381\n",
            "Epoch 251/300\n",
            " - 0s - loss: 2.2180e-04 - acc: 1.0000 - val_loss: 0.6724 - val_acc: 0.8381\n",
            "Epoch 252/300\n",
            " - 0s - loss: 2.2189e-04 - acc: 1.0000 - val_loss: 0.6708 - val_acc: 0.8524\n",
            "Epoch 253/300\n",
            " - 1s - loss: 2.5378e-04 - acc: 1.0000 - val_loss: 0.6718 - val_acc: 0.8476\n",
            "Epoch 254/300\n",
            " - 0s - loss: 6.6504e-04 - acc: 1.0000 - val_loss: 0.6831 - val_acc: 0.8476\n",
            "Epoch 255/300\n",
            " - 0s - loss: 3.2998e-04 - acc: 1.0000 - val_loss: 0.7066 - val_acc: 0.8286\n",
            "Epoch 256/300\n",
            " - 1s - loss: 3.9372e-04 - acc: 1.0000 - val_loss: 0.7137 - val_acc: 0.8143\n",
            "Epoch 257/300\n",
            " - 0s - loss: 6.4055e-04 - acc: 1.0000 - val_loss: 0.6612 - val_acc: 0.8429\n",
            "Epoch 258/300\n",
            " - 0s - loss: 3.2805e-04 - acc: 1.0000 - val_loss: 0.6833 - val_acc: 0.8429\n",
            "Epoch 259/300\n",
            " - 0s - loss: 5.1383e-04 - acc: 1.0000 - val_loss: 0.7035 - val_acc: 0.8381\n",
            "Epoch 260/300\n",
            " - 0s - loss: 2.9497e-04 - acc: 1.0000 - val_loss: 0.6768 - val_acc: 0.8524\n",
            "Epoch 261/300\n",
            " - 0s - loss: 2.7223e-04 - acc: 1.0000 - val_loss: 0.6855 - val_acc: 0.8476\n",
            "Epoch 262/300\n",
            " - 0s - loss: 4.9394e-04 - acc: 1.0000 - val_loss: 0.6983 - val_acc: 0.8286\n",
            "Epoch 263/300\n",
            " - 0s - loss: 3.4637e-04 - acc: 1.0000 - val_loss: 0.7011 - val_acc: 0.8333\n",
            "Epoch 264/300\n",
            " - 0s - loss: 3.2684e-04 - acc: 1.0000 - val_loss: 0.6910 - val_acc: 0.8429\n",
            "Epoch 265/300\n",
            " - 1s - loss: 5.1259e-04 - acc: 1.0000 - val_loss: 0.6904 - val_acc: 0.8333\n",
            "Epoch 266/300\n",
            " - 0s - loss: 4.8334e-04 - acc: 1.0000 - val_loss: 0.6862 - val_acc: 0.8286\n",
            "Epoch 267/300\n",
            " - 0s - loss: 5.6177e-04 - acc: 1.0000 - val_loss: 0.6698 - val_acc: 0.8381\n",
            "Epoch 268/300\n",
            " - 0s - loss: 4.7025e-04 - acc: 1.0000 - val_loss: 0.6429 - val_acc: 0.8524\n",
            "Epoch 269/300\n",
            " - 0s - loss: 3.8039e-04 - acc: 1.0000 - val_loss: 0.6529 - val_acc: 0.8476\n",
            "Epoch 270/300\n",
            " - 0s - loss: 4.1474e-04 - acc: 1.0000 - val_loss: 0.6436 - val_acc: 0.8429\n",
            "Epoch 271/300\n",
            " - 0s - loss: 2.9324e-04 - acc: 1.0000 - val_loss: 0.6612 - val_acc: 0.8476\n",
            "Epoch 272/300\n",
            " - 0s - loss: 2.4146e-04 - acc: 1.0000 - val_loss: 0.6623 - val_acc: 0.8524\n",
            "Epoch 273/300\n",
            " - 1s - loss: 2.9744e-04 - acc: 1.0000 - val_loss: 0.6719 - val_acc: 0.8571\n",
            "Epoch 274/300\n",
            " - 0s - loss: 3.1799e-04 - acc: 1.0000 - val_loss: 0.6587 - val_acc: 0.8571\n",
            "Epoch 275/300\n",
            " - 0s - loss: 3.1214e-04 - acc: 1.0000 - val_loss: 0.6619 - val_acc: 0.8381\n",
            "Epoch 276/300\n",
            " - 0s - loss: 9.8983e-04 - acc: 1.0000 - val_loss: 0.6860 - val_acc: 0.8286\n",
            "Epoch 277/300\n",
            " - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.7213 - val_acc: 0.8286\n",
            "Epoch 278/300\n",
            " - 0s - loss: 0.0030 - acc: 0.9989 - val_loss: 0.6265 - val_acc: 0.8619\n",
            "Epoch 279/300\n",
            " - 0s - loss: 0.0039 - acc: 1.0000 - val_loss: 0.7421 - val_acc: 0.8000\n",
            "Epoch 280/300\n",
            " - 0s - loss: 0.0063 - acc: 0.9989 - val_loss: 0.7074 - val_acc: 0.8143\n",
            "Epoch 281/300\n",
            " - 0s - loss: 0.0077 - acc: 0.9978 - val_loss: 0.6518 - val_acc: 0.8333\n",
            "Epoch 282/300\n",
            " - 0s - loss: 0.0067 - acc: 0.9989 - val_loss: 0.8116 - val_acc: 0.8190\n",
            "Epoch 283/300\n",
            " - 0s - loss: 0.0065 - acc: 0.9989 - val_loss: 0.7734 - val_acc: 0.8238\n",
            "Epoch 284/300\n",
            " - 0s - loss: 0.0108 - acc: 0.9966 - val_loss: 0.7710 - val_acc: 0.8333\n",
            "Epoch 285/300\n",
            " - 0s - loss: 0.0202 - acc: 0.9933 - val_loss: 0.7433 - val_acc: 0.8429\n",
            "Epoch 286/300\n",
            " - 0s - loss: 0.0197 - acc: 0.9938 - val_loss: 0.9334 - val_acc: 0.8048\n",
            "Epoch 287/300\n",
            " - 0s - loss: 0.0080 - acc: 0.9983 - val_loss: 0.6514 - val_acc: 0.8429\n",
            "Epoch 288/300\n",
            " - 0s - loss: 0.0040 - acc: 0.9994 - val_loss: 0.8096 - val_acc: 0.8381\n",
            "Epoch 289/300\n",
            " - 0s - loss: 0.0025 - acc: 0.9994 - val_loss: 0.8026 - val_acc: 0.8333\n",
            "Epoch 290/300\n",
            " - 0s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.8016 - val_acc: 0.8333\n",
            "Epoch 291/300\n",
            " - 1s - loss: 0.0035 - acc: 0.9989 - val_loss: 0.7965 - val_acc: 0.8048\n",
            "Epoch 292/300\n",
            " - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.7797 - val_acc: 0.8095\n",
            "Epoch 293/300\n",
            " - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.7549 - val_acc: 0.8238\n",
            "Epoch 294/300\n",
            " - 0s - loss: 0.0015 - acc: 1.0000 - val_loss: 0.7367 - val_acc: 0.8143\n",
            "Epoch 295/300\n",
            " - 1s - loss: 0.0022 - acc: 0.9989 - val_loss: 0.7486 - val_acc: 0.8238\n",
            "Epoch 296/300\n",
            " - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6835 - val_acc: 0.8381\n",
            "Epoch 297/300\n",
            " - 0s - loss: 9.2899e-04 - acc: 1.0000 - val_loss: 0.7368 - val_acc: 0.8190\n",
            "Epoch 298/300\n",
            " - 0s - loss: 5.0639e-04 - acc: 1.0000 - val_loss: 0.7186 - val_acc: 0.8286\n",
            "Epoch 299/300\n",
            " - 0s - loss: 6.8123e-04 - acc: 1.0000 - val_loss: 0.7340 - val_acc: 0.8143\n",
            "Epoch 300/300\n",
            " - 0s - loss: 6.7007e-04 - acc: 1.0000 - val_loss: 0.7599 - val_acc: 0.8190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjupDziLszWs",
        "colab_type": "code",
        "outputId": "d391c17b-b3b3-4849-8348-3706a18acb35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "epochs = np.argmin(model_fit_history.history['val_loss']) + 1\n",
        "print(f'Stop training at {epochs} epochs')\n",
        "\n",
        "# Merge training and validation data\n",
        "X_train = np.concatenate([X['Train'], X['Validation']])\n",
        "Y_train = np.concatenate([Y['Train'], Y['Validation']])\n",
        "\n",
        "# Randomly shuffle X and Y\n",
        "shuffle_index = np.random.permutation(len(X_train))\n",
        "X_train = X_train[shuffle_index]\n",
        "Y_train = Y_train[shuffle_index]\n",
        "model = build_fully_connected(input_shape=X_train.shape[1:], num_classes=num_classes)\n",
        "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_fit_history = model.fit(X_train, Y_train, batch_size=64, epochs=epochs, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fb4be8860d2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fit_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Stop training at {epochs} epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Merge training and validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw6-D7MVtgHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict_classes(X['Test'], verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI9sify6tsLF",
        "colab_type": "code",
        "outputId": "de482a2f-880d-4137-f5de-7f4fa320124f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "source": [
        "y_test = np.nonzero(Y['Test'])[1]\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model predication accuracy: {accuracy:.3f}')\n",
        "print(f'\\nClassification report:\\n {classification_report(y_test, y_pred)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model predication accuracy: 0.886\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      0.80      0.89        10\n",
            "           2       1.00      0.90      0.95        10\n",
            "           3       0.69      0.90      0.78        10\n",
            "           4       0.75      0.90      0.82        10\n",
            "           5       1.00      0.80      0.89        10\n",
            "           6       1.00      0.30      0.46        10\n",
            "           7       0.77      1.00      0.87        10\n",
            "           8       1.00      0.80      0.89        10\n",
            "           9       1.00      0.90      0.95        10\n",
            "          10       1.00      1.00      1.00        10\n",
            "          11       0.75      0.90      0.82        10\n",
            "          12       0.69      0.90      0.78        10\n",
            "          13       0.91      1.00      0.95        10\n",
            "          14       0.90      0.90      0.90        10\n",
            "          15       1.00      1.00      1.00        10\n",
            "          16       0.83      1.00      0.91        10\n",
            "          17       0.83      1.00      0.91        10\n",
            "          18       1.00      0.70      0.82        10\n",
            "          19       0.91      1.00      0.95        10\n",
            "          20       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.89       210\n",
            "   macro avg       0.91      0.89      0.88       210\n",
            "weighted avg       0.91      0.89      0.88       210\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpmleK4WtykM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}